{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOaP6dkXBkjH/7G4/tLac5H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prompt-lab/workshop_42/blob/main/01/1_GPT_API_%EC%82%AC%EC%9A%A9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPk_i5MVTs_E",
        "outputId": "d19dfe47-86aa-4fd3-af31-3c5a5188c5e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.4-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.3/269.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.4 yarl-1.9.1\n"
          ]
        }
      ],
      "source": [
        "pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "X2O0Y0O4T1z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "프롬프트와 토큰\n",
        "temperature = 모델이 리스크를 감수하면서 더 확률이 낮은 토큰을 고르게 됨"
      ],
      "metadata": {
        "id": "XyYcOIU-UIGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = \"\"  "
      ],
      "metadata": {
        "id": "W2Ekda5zUEiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "systemPrompt = '''\n",
        "Suggest three name for innovative programming school\n",
        "'''"
      ],
      "metadata": {
        "id": "xPqXoa0PWKyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = [\n",
        "    {\"role\": \"system\", \"content\": systemPrompt}\n",
        "]"
      ],
      "metadata": {
        "id": "9W4QXXy9VKEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=conversation,\n",
        "    temperature=1,\n",
        "    max_tokens=100,\n",
        "    n=2,\n",
        "    stop=None,\n",
        ")"
      ],
      "metadata": {
        "id": "VkjoyVRmU-Ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**choices** → 답변( n 옵션에 들어가는 수에 따라, n개의 답변을 생성한다. index로 확인 가능 )\n",
        "\n",
        "**model, object** → chat.completion, completion의 차이 \n",
        "\n",
        "텍스트가 생성되는 맥락이 다르다. Completion은, 주어진 프롬프트나 문장의 ‘조각’을 ‘완성’하는 텍스트를 생성한다. 티끌 모아를 넣으면, 아마 태산을 내놓을 것이다.\n",
        "\n",
        "채팅 완성은, 대화 또는 대화의 맥락에서 텍스트를 생성하는 것을 의미한다. 문맥과 관련이 있고, 자연스러운 대화같은 텍스트를 생성한다.\n",
        "\n",
        "**usage** → 사용량. 우리가 보낸 토큰과, gpt가 생성한 토큰이 동시에 과금된다.\n",
        "\n",
        "stop : API가 완성했다.\n",
        "\n",
        "length : max_tokens에 걸렸다\n",
        "\n",
        "content_filter : 윤리필터에 걸렸다\n",
        "\n",
        "null : 실패"
      ],
      "metadata": {
        "id": "vg76O9b8W0QV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIeZ4XO5VZa1",
        "outputId": "90b95ed9-7bd1-4619-e25c-274a26a3ea45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"content\": \"1. CodeCrafters Academy\\n2. TechTrailblazers Institute\\n3. ByteBuilders Academy\",\n",
            "        \"role\": \"assistant\"\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 1,\n",
            "      \"message\": {\n",
            "        \"content\": \"1. CodeCraft\\n2. MindMakers\\n3. RoboGenius\",\n",
            "        \"role\": \"assistant\"\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1682425927,\n",
            "  \"id\": \"chatcmpl-79C7zKnnt4Yd3LpfiGPlYcqStJogC\",\n",
            "  \"model\": \"gpt-3.5-turbo-0301\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 37,\n",
            "    \"prompt_tokens\": 18,\n",
            "    \"total_tokens\": 55\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNu4VsUgWUxy",
        "outputId": "9805a316-fe43-4edb-81c6-70f0a1cc8631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, sir. Can I see your identification, please?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "  messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
        "    ]\n",
        "```"
      ],
      "metadata": {
        "id": "xMwoV7qrZwns"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 입력값을 더 명확하게 한다.\n",
        "2. 출력값의 포맷을 명확히 한다.\n",
        "3. 대답하기 전에 모델 스스로 좀 생각을(토론하던지, 장단점을 고려하던지) 하라고 한다."
      ],
      "metadata": {
        "id": "ySQznVXXaEkH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WKb1EfoIcKRs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}