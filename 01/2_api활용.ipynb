{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "19UIk9BmzYl5_CHzEt0mOsvvVY05y_a35",
      "authorship_tag": "ABX9TyPwQhNR1uy+/AQZiR5wU1uY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prompt-lab/workshop_42/blob/main/01/2_api%ED%99%9C%EC%9A%A9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r41TsbGmaeNu",
        "outputId": "1ebd0580-e4a2-46e7-ef37-a39f8eecd04e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.4-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.3/269.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.4 yarl-1.9.1\n"
          ]
        }
      ],
      "source": [
        "pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "He9pYJE4ahyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Colab 구글 드라이브 연동\n",
        "\n",
        "폴더 모양 아이콘을 클릭해줍니다.\n",
        "\n",
        "그 후 드라이브 모양 아이콘을 클릭해줍니다."
      ],
      "metadata": {
        "id": "EuhJ6ky9aqzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "openai.api_key = \"\""
      ],
      "metadata": {
        "id": "DfoacZgnaziV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GyWjXXi_a8Kf",
        "outputId": "1a0854f4-b1c6-4ac9-e227-a88c2c643d3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir(\"test_folder\")"
      ],
      "metadata": {
        "id": "w6CLe8Yga9AT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "systemPrompt = '''\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "N-yzjTaMbhxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "userInput = \"  \""
      ],
      "metadata": {
        "id": "fmiAd4QdbnQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = [\n",
        "    {\"role\": \"system\", \"content\": systemPrompt},\n",
        "    {\"role\": \"user\", \"content\": userInput}\n",
        "]"
      ],
      "metadata": {
        "id": "2t7UFIQCbkXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Planner = openai.ChatCompletion.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=conversation,\n",
        "    temperature=0.5,\n",
        "    max_tokens=100,\n",
        "    n=1,\n",
        "    stop=None,\n",
        ")"
      ],
      "metadata": {
        "id": "HC0uJln5bFRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plannerAnswer = Planner.choices[0].message.content\n",
        "print(plannerAnswer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMkY-35xb0gf",
        "outputId": "1516d6d7-0f95-43c0-97e0-96da3211e86a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[mkdir] : project\n",
            "[build] : project/main.py : Create a file named main.py that imports functions from utils.py and processes.py. Call the functions from these files and print the results.\n",
            "[build] : project/utils.py : Create a file named utils.py that contains utility functions such as data loading, data preprocessing, and data manipulation functions.\n",
            "[build] : project/processes.py : Create a file named processes.py that contains functions for processing data, such as data analysis, data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*이탤릭체 텍스트*#format example\n",
        "[명령어] : 타겟 : 지시 \n",
        "```\n",
        "[mkdir] : project\n",
        "[build] : project/main.py : Create a file named main.py that imports functions from utils.py and processes.py. Call the functions from these files and print the results.\n",
        "[build] : project/utils.py : Create a file named utils.py that contains utility functions such as data loading, data preprocessing, and data manipulation functions.\n",
        "[build] : project/processes.py : Create a file named processes.py that contains functions for processing data, such as data analysis, data\n",
        "```"
      ],
      "metadata": {
        "id": "wvogTEKah07x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "builderPrompt = '''\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "4jarzNSKh1V_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mkdir(folder):\n",
        "    os.mkdir(folder)\n",
        "\n",
        "def build(target, instruction):\n",
        "    Builder = openai.ChatCompletion.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=[\n",
        "    {\"role\": \"system\", \"content\": builderPrompt + instruction},\n",
        "],\n",
        "    temperature=0,\n",
        "    max_tokens=100,\n",
        "    n=1,\n",
        "    stop=None,\n",
        ")\n",
        "    code = Builder.choices[0].message.content\n",
        "    with open(target, 'w') as file:\n",
        "      file.write(code)\n",
        "    "
      ],
      "metadata": {
        "id": "mqPUA1TUdWgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for line in plannerAnswer.split('\\n'):\n",
        "    print(line)\n",
        "    if line.startswith('[mkdir]'):\n",
        "        folder = line.split(': ')[1].strip()\n",
        "        mkdir(folder)\n",
        "    elif line.startswith('[build]'):\n",
        "        target = line.split(': ')[1].strip()\n",
        "        instruction = line.split(': ')[2].strip()\n",
        "        build(target, instruction)\n",
        "    else:\n",
        "      print(\"wrong command\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1t36l0vQc4Ck",
        "outputId": "f3f6abdc-e6e8-4833-daa4-04eea9179c2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[mkdir] : project\n",
            "[build] : project/main.py : Create a file named main.py that imports functions from utils.py and processes.py. Call the functions from these files and print the results.\n",
            "[build] : project/utils.py : Create a file named utils.py that contains utility functions such as data loading, data preprocessing, and data manipulation functions.\n",
            "[build] : project/processes.py : Create a file named processes.py that contains functions for processing data, such as data analysis, data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#warning : delete folder\n",
        "import shutil\n",
        "\n",
        "shutil.rmtree('project')"
      ],
      "metadata": {
        "id": "0mmygbxMdlze"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}